Проект с выполнением задач по курсу Data Science-1.

Для Hw4 файл с данными не добавляла, т.к. очень большой, гит не пропускает. 
Относительно метрик: самая высокая  - Accuracy: 0.7628 с использование CatBoost классификатора.
Пробовала повышать max_features в TfidfVectorizer либо параметры в конструкторе классификатора - оказывает сильное влияние на оперативную память, нужно гораздо больше ресурсов (особеннно в случае с QuadraticDiscriminantAnalysis). Создавала memory-mapped файл для плотной матрицы, но ресурсы тоже тянет сильно.

Hw5: самым оптимальным регрессором для текущего датасета оказался DecisionTreeRegressor(R-squared (R2): 0.9938584421820219). Относительно KNeighborsRegressor удалось поднять метрику только до (R²): 0.34 за счет подбора n_neighbors.
